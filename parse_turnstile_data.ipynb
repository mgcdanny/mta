{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import iglob\n",
    "from itertools import chain\n",
    "from sqlalchemy import create_engine\n",
    "mta_engine = create_engine('sqlite:///mta.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_raw_post_20141018():\n",
    "    \"\"\"\n",
    "    \n",
    "        CREATE TABLE raw (\n",
    "        \"index\" BIGINT, \n",
    "        \"C/A\" TEXT, \n",
    "        \"UNIT\" TEXT, \n",
    "        \"SCP\" TEXT, \n",
    "        \"STATION\" TEXT, \n",
    "        \"LINENAME\" TEXT, \n",
    "        \"DIVISION\" TEXT, \n",
    "        \"DATE\" TEXT, \n",
    "        \"TIME\" TEXT, \n",
    "        \"DESC\" TEXT, \n",
    "        \"ENTRIES\" BIGINT, \n",
    "        \"EXITS\" BIGINT\n",
    "    );\n",
    "\n",
    "    \"\"\"\n",
    "    mta_engine = create_engine('sqlite:///mta.db')\n",
    "    for data_file in iglob('./data/*.txt'):\n",
    "        if strip_file_date(data_file) >= 141018:\n",
    "            with open(data_file) as ofile:\n",
    "                print(data_file)\n",
    "                df = pd.read_csv(ofile, low_memory=False)\n",
    "                df.to_sql(name='raw', con=mta_engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_station_lookup(engine):\n",
    "    #I think knowing the C/A is sufficient to determine the Station\n",
    "    tbl = mta_engine.execute(\"CREATE TABLE IF NOT EXISTS main.station_lookup AS SELECT DISTINCT raw.'C/A', STATION FROM raw\")\n",
    "    tbl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    import_raw_post_20141018()\n",
    "    create_station_lookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_pre_20141018(csv_path):\n",
    "    \"\"\"MTA turnstile .txt files before 20141018 have a strange format.\n",
    "    This function makes that format the same as the post 20141018 format\n",
    "    station_lookup is a csv file that can find station name based on ('C/A', UNIT, SCP)\n",
    "    \"\"\"\n",
    "    header_names = ['C/A','UNIT','SCP','DATE1','TIME1','DESC1','ENTRIES1','EXITS1','DATE2','TIME2','DESC2','ENTRIES2','EXITS2','DATE3','TIME3','DESC3','ENTRIES3','EXITS3','DATE4','TIME4','DESC4','ENTRIES4','EXITS4','DATE5','TIME5','DESC5','ENTRIES5','EXITS5','DATE6','TIME6','DESC6','ENTRIES6','EXITS6','DATE7','TIME7','DESC7','ENTRIES7','EXITS7','DATE8','TIME8','DESC8','ENTRIES8','EXITS8']\n",
    "    df = pd.read_csv(csv_path, header=None, names=header_names, low_memory=False)\n",
    "    splits = [\"\"\"C/A,UNIT,SCP,DATE{index},TIME{index},DESC{index},ENTRIES{index},EXITS{index}\"\"\".format(index=i).split(',') for i in range(1,9)]\n",
    "    result = []\n",
    "    clean_column_names = ['C/A','UNIT','SCP','DATE','TIME','DESC','ENTRIES','EXITS']\n",
    "    for split in splits:\n",
    "        temp = df[split]\n",
    "        temp.columns = clean_column_names\n",
    "        result.append(temp)\n",
    "    df_long = pd.concat(result)\n",
    "    return df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_file_date(file_path):\n",
    "    \"\"\"expecting the files to look like ./data/turnstile_100612.txt\n",
    "    \n",
    "    >>> strip_file_date('./data/turnstile_100612.txt') == 100612\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return int(file_path.split('_')[1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_headers(headers):\n",
    "    #remove trailing whitespace from the column names\n",
    "    return [c.strip().lower() for c in headers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station_lookup = pd.read_sql('select distinct \"C/A\", STATION from station_lookup', mta_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/turnstile_100505.txt\n",
      "./data/turnstile_100508.txt\n",
      "./data/turnstile_100515.txt\n",
      "./data/turnstile_100522.txt\n",
      "./data/turnstile_100605.txt\n",
      "./data/turnstile_100612.txt\n",
      "./data/turnstile_100619.txt\n",
      "./data/turnstile_100626.txt\n",
      "./data/turnstile_100703.txt\n",
      "./data/turnstile_100710.txt\n",
      "./data/turnstile_100717.txt\n",
      "./data/turnstile_100724.txt\n",
      "./data/turnstile_100731.txt\n",
      "./data/turnstile_100807.txt\n",
      "./data/turnstile_100814.txt\n",
      "./data/turnstile_100821.txt\n",
      "./data/turnstile_100828.txt\n",
      "./data/turnstile_100904.txt\n",
      "./data/turnstile_100911.txt\n",
      "./data/turnstile_100918.txt\n",
      "./data/turnstile_100925.txt\n",
      "./data/turnstile_101002.txt\n",
      "./data/turnstile_101009.txt\n",
      "./data/turnstile_101016.txt\n",
      "./data/turnstile_101023.txt\n",
      "./data/turnstile_101030.txt\n",
      "./data/turnstile_101106.txt\n",
      "./data/turnstile_101113.txt\n",
      "./data/turnstile_101120.txt\n",
      "./data/turnstile_101127.txt\n",
      "./data/turnstile_101204.txt\n",
      "./data/turnstile_101211.txt\n",
      "./data/turnstile_101218.txt\n",
      "./data/turnstile_101225.txt\n",
      "./data/turnstile_110101.txt\n",
      "./data/turnstile_110108.txt\n",
      "./data/turnstile_110115.txt\n",
      "./data/turnstile_110122.txt\n",
      "./data/turnstile_110129.txt\n",
      "./data/turnstile_110205.txt\n",
      "./data/turnstile_110212.txt\n",
      "./data/turnstile_110219.txt\n",
      "./data/turnstile_110226.txt\n",
      "./data/turnstile_110305.txt\n",
      "./data/turnstile_110312.txt\n",
      "./data/turnstile_110319.txt\n",
      "./data/turnstile_110326.txt\n",
      "./data/turnstile_110402.txt\n",
      "./data/turnstile_110409.txt\n",
      "./data/turnstile_110416.txt\n",
      "./data/turnstile_110423.txt\n",
      "./data/turnstile_110430.txt\n",
      "./data/turnstile_110507.txt\n",
      "./data/turnstile_110514.txt\n",
      "./data/turnstile_110521.txt\n",
      "./data/turnstile_110528.txt\n",
      "./data/turnstile_110604.txt\n",
      "./data/turnstile_110611.txt\n",
      "./data/turnstile_110618.txt\n",
      "./data/turnstile_110625.txt\n",
      "./data/turnstile_110702.txt\n",
      "./data/turnstile_110709.txt\n",
      "./data/turnstile_110716.txt\n",
      "./data/turnstile_110723.txt\n",
      "./data/turnstile_110730.txt\n",
      "./data/turnstile_110806.txt\n",
      "./data/turnstile_110813.txt\n",
      "./data/turnstile_110820.txt\n",
      "./data/turnstile_110827.txt\n",
      "./data/turnstile_110903.txt\n",
      "./data/turnstile_110910.txt\n",
      "./data/turnstile_110917.txt\n",
      "./data/turnstile_110924.txt\n",
      "./data/turnstile_111001.txt\n",
      "./data/turnstile_111008.txt\n",
      "./data/turnstile_111015.txt\n",
      "./data/turnstile_111022.txt\n",
      "./data/turnstile_111029.txt\n",
      "./data/turnstile_111105.txt\n",
      "./data/turnstile_111112.txt\n",
      "./data/turnstile_111119.txt\n",
      "./data/turnstile_111126.txt\n",
      "./data/turnstile_111203.txt\n",
      "./data/turnstile_111210.txt\n",
      "./data/turnstile_111219.txt\n",
      "./data/turnstile_111224.txt\n",
      "./data/turnstile_111231.txt\n",
      "./data/turnstile_120107.txt\n",
      "./data/turnstile_120114.txt\n",
      "./data/turnstile_120121.txt\n",
      "./data/turnstile_120128.txt\n",
      "./data/turnstile_120204.txt\n",
      "./data/turnstile_120211.txt\n",
      "./data/turnstile_120218.txt\n",
      "./data/turnstile_120225.txt\n",
      "./data/turnstile_120303.txt\n",
      "./data/turnstile_120310.txt\n",
      "./data/turnstile_120317.txt\n",
      "./data/turnstile_120324.txt\n",
      "./data/turnstile_120331.txt\n",
      "./data/turnstile_120407.txt\n",
      "./data/turnstile_120414.txt\n",
      "./data/turnstile_120421.txt\n",
      "./data/turnstile_120428.txt\n",
      "./data/turnstile_120505.txt\n",
      "./data/turnstile_120512.txt\n",
      "./data/turnstile_120519.txt\n",
      "./data/turnstile_120526.txt\n",
      "./data/turnstile_120602.txt\n",
      "./data/turnstile_120609.txt\n",
      "./data/turnstile_120616.txt\n",
      "./data/turnstile_120623.txt\n",
      "./data/turnstile_120630.txt\n",
      "./data/turnstile_120707.txt\n",
      "./data/turnstile_120714.txt\n",
      "./data/turnstile_120721.txt\n",
      "./data/turnstile_120728.txt\n",
      "./data/turnstile_120804.txt\n",
      "./data/turnstile_120811.txt\n",
      "./data/turnstile_120818.txt\n",
      "./data/turnstile_120825.txt\n",
      "./data/turnstile_120901.txt\n",
      "./data/turnstile_120908.txt\n",
      "./data/turnstile_120915.txt\n",
      "./data/turnstile_120922.txt\n",
      "./data/turnstile_120929.txt\n",
      "./data/turnstile_121006.txt\n",
      "./data/turnstile_121013.txt\n",
      "./data/turnstile_121020.txt\n",
      "./data/turnstile_121027.txt\n",
      "./data/turnstile_121103.txt\n",
      "./data/turnstile_121110.txt\n",
      "./data/turnstile_121117.txt\n",
      "./data/turnstile_121124.txt\n",
      "./data/turnstile_121201.txt\n",
      "./data/turnstile_121208.txt\n",
      "./data/turnstile_121215.txt\n",
      "./data/turnstile_121222.txt\n",
      "./data/turnstile_121229.txt\n",
      "./data/turnstile_130105.txt\n",
      "./data/turnstile_130112.txt\n",
      "./data/turnstile_130119.txt\n",
      "./data/turnstile_130126.txt\n",
      "./data/turnstile_130202.txt\n",
      "./data/turnstile_130209.txt\n",
      "./data/turnstile_130216.txt\n",
      "./data/turnstile_130223.txt\n",
      "./data/turnstile_130302.txt\n",
      "./data/turnstile_130309.txt\n",
      "./data/turnstile_130316.txt\n",
      "./data/turnstile_130323.txt\n",
      "./data/turnstile_130330.txt\n",
      "./data/turnstile_130406.txt\n",
      "./data/turnstile_130413.txt\n",
      "./data/turnstile_130420.txt\n",
      "./data/turnstile_130427.txt\n",
      "./data/turnstile_130504.txt\n",
      "./data/turnstile_130511.txt\n",
      "./data/turnstile_130518.txt\n",
      "./data/turnstile_130525.txt\n",
      "./data/turnstile_130601.txt\n",
      "./data/turnstile_130608.txt\n",
      "./data/turnstile_130615.txt\n",
      "./data/turnstile_130622.txt\n",
      "./data/turnstile_130629.txt\n",
      "./data/turnstile_130706.txt\n",
      "./data/turnstile_130713.txt\n",
      "./data/turnstile_130720.txt\n",
      "./data/turnstile_130727.txt\n",
      "./data/turnstile_130803.txt\n",
      "./data/turnstile_130810.txt\n",
      "./data/turnstile_130817.txt\n",
      "./data/turnstile_130824.txt\n",
      "./data/turnstile_130831.txt\n",
      "./data/turnstile_130907.txt\n",
      "./data/turnstile_130914.txt\n",
      "./data/turnstile_130921.txt\n",
      "./data/turnstile_130928.txt\n",
      "./data/turnstile_131005.txt\n",
      "./data/turnstile_131012.txt\n",
      "./data/turnstile_131019.txt\n",
      "./data/turnstile_131026.txt\n",
      "./data/turnstile_131102.txt\n",
      "./data/turnstile_131109.txt\n",
      "./data/turnstile_131116.txt\n",
      "./data/turnstile_131123.txt\n",
      "./data/turnstile_131130.txt\n",
      "./data/turnstile_131207.txt\n",
      "./data/turnstile_131214.txt\n",
      "./data/turnstile_131221.txt\n",
      "./data/turnstile_131228.txt\n",
      "./data/turnstile_140104.txt\n",
      "./data/turnstile_140111.txt\n",
      "./data/turnstile_140118.txt\n",
      "./data/turnstile_140125.txt\n",
      "./data/turnstile_140201.txt\n",
      "./data/turnstile_140208.txt\n",
      "./data/turnstile_140215.txt\n",
      "./data/turnstile_140222.txt\n",
      "./data/turnstile_140301.txt\n",
      "./data/turnstile_140308.txt\n",
      "./data/turnstile_140315.txt\n",
      "./data/turnstile_140322.txt\n",
      "./data/turnstile_140329.txt\n",
      "./data/turnstile_140405.txt\n",
      "./data/turnstile_140412.txt\n",
      "./data/turnstile_140419.txt\n",
      "./data/turnstile_140426.txt\n",
      "./data/turnstile_140503.txt\n",
      "./data/turnstile_140510.txt\n",
      "./data/turnstile_140517.txt\n",
      "./data/turnstile_140524.txt\n",
      "./data/turnstile_140531.txt\n",
      "./data/turnstile_140607.txt\n",
      "./data/turnstile_140614.txt\n",
      "./data/turnstile_140621.txt\n",
      "./data/turnstile_140628.txt\n",
      "./data/turnstile_140705.txt\n",
      "./data/turnstile_140712.txt\n",
      "./data/turnstile_140719.txt\n",
      "./data/turnstile_140726.txt\n",
      "./data/turnstile_140802.txt\n",
      "./data/turnstile_140809.txt\n",
      "./data/turnstile_140816.txt\n",
      "./data/turnstile_140823.txt\n",
      "./data/turnstile_140830.txt\n",
      "./data/turnstile_140906.txt\n",
      "./data/turnstile_140913.txt\n",
      "./data/turnstile_140920.txt\n",
      "./data/turnstile_140927.txt\n",
      "./data/turnstile_141004.txt\n",
      "./data/turnstile_141011.txt\n",
      "./data/turnstile_141018.txt\n",
      "./data/turnstile_141025.txt\n",
      "./data/turnstile_141101.txt\n",
      "./data/turnstile_141108.txt\n",
      "./data/turnstile_141115.txt\n",
      "./data/turnstile_141122.txt\n",
      "./data/turnstile_141129.txt\n",
      "./data/turnstile_141206.txt\n",
      "./data/turnstile_141213.txt\n",
      "./data/turnstile_141220.txt\n",
      "./data/turnstile_141227.txt\n",
      "./data/turnstile_150103.txt\n",
      "./data/turnstile_150110.txt\n",
      "./data/turnstile_150117.txt\n",
      "./data/turnstile_150124.txt\n",
      "./data/turnstile_150131.txt\n",
      "./data/turnstile_150207.txt\n",
      "./data/turnstile_150214.txt\n",
      "./data/turnstile_150221.txt\n",
      "./data/turnstile_150228.txt\n",
      "./data/turnstile_150307.txt\n",
      "./data/turnstile_150314.txt\n",
      "./data/turnstile_150321.txt\n",
      "./data/turnstile_150328.txt\n",
      "./data/turnstile_150404.txt\n",
      "./data/turnstile_150411.txt\n",
      "./data/turnstile_150418.txt\n",
      "./data/turnstile_150425.txt\n",
      "./data/turnstile_150502.txt\n",
      "./data/turnstile_150509.txt\n",
      "./data/turnstile_150516.txt\n",
      "./data/turnstile_150523.txt\n",
      "./data/turnstile_150530.txt\n",
      "./data/turnstile_150606.txt\n",
      "./data/turnstile_150613.txt\n",
      "./data/turnstile_150620.txt\n",
      "./data/turnstile_150627.txt\n",
      "./data/turnstile_150704.txt\n",
      "./data/turnstile_150711.txt\n",
      "./data/turnstile_150718.txt\n",
      "./data/turnstile_150725.txt\n",
      "./data/turnstile_150801.txt\n",
      "./data/turnstile_150808.txt\n",
      "./data/turnstile_150815.txt\n",
      "./data/turnstile_150822.txt\n"
     ]
    }
   ],
   "source": [
    "for data_file in iglob('./data/*.txt'):\n",
    "    print(data_file)\n",
    "    try:\n",
    "        with open(data_file) as data:\n",
    "            if strip_file_date(data_file) < 141018:\n",
    "                df = fix_pre_20141018(data_file)\n",
    "                df = pd.merge(df, station_lookup, on='C/A') #consider making this a left join\n",
    "            else:\n",
    "                df = pd.read_csv(data, low_memory=False)\n",
    "            #remove trailing whitespace from the column names\n",
    "            df.columns = [c.strip().lower() for c in df.columns]\n",
    "            #just use 'regular' records\n",
    "            df = df[df.desc == 'REGULAR']\n",
    "            #create proper timestamp column\n",
    "            df['ts'] = pd.to_datetime(df.date + ' ' + df.time)\n",
    "            #test for uniquness\n",
    "            #assert sum(df[['ts','c/a','unit', 'scp', 'station']].duplicated()) == 0\n",
    "            #subset to minimum required set of vars\n",
    "            df = df[['c/a','unit','scp','station','entries','exits', 'ts']]\n",
    "            #order by tunrstile identity and timeseries\n",
    "            df = df.sort(['station','c/a','unit','scp','ts'])\n",
    "            df = df.set_index(['station','c/a','unit','scp','ts'])\n",
    "            #get the delta between observations and remove outliers and missing values\n",
    "            gb = df.groupby(level=['station','c/a','unit','scp']).diff()\n",
    "            gb = gb.fillna(-1)\n",
    "            entries = gb[gb.entries >= 0]['entries']\n",
    "            exits = gb[gb.exits >= 0]['exits']\n",
    "            #only keep observations less than or equal to the 99% quantile\n",
    "            #TODO: consider removing outliers at the station level, instead of across the board\n",
    "            entries = entries[entries <= entries.quantile(.99)]\n",
    "            exits = exits[exits <= exits.quantile(.99)]\n",
    "            #create a clean dataframe\n",
    "            df_clean = pd.DataFrame([entries.groupby(level=['station', 'ts']).sum(),exits.groupby(level=['station', 'ts']).sum()]).T\n",
    "            #aggregate to the 'day' level instead of hourly\n",
    "            df_clean = df_clean.reset_index()\n",
    "            df_clean['ts'] = df_clean['ts'].apply(lambda x: x.date())\n",
    "            df_clean = df_clean.rename(columns={'ts': 'day'})\n",
    "            df_clean = df_clean.groupby(['station', 'day']).sum()\n",
    "            df_clean.to_sql(name='clean_data', con=mta_engine, if_exists='append')\n",
    "    except Exception as e:\n",
    "        with open('error.log', 'a') as errors:\n",
    "            errors.write(data_file)\n",
    "            errors.write(str(e))\n",
    "            errors.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
